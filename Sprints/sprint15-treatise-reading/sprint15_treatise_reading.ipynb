{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint15-treatise-reading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqwJPjm788rC"
      },
      "source": [
        "#Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\n",
        "https://arxiv.org/pdf/1506.01497.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fY2iFTh8zbB"
      },
      "source": [
        "##(1) What kind of method exists in the field of object detection?\n",
        "```markdown\n",
        "Mentioned methods are SPPnet, Fast R-CNN, RPN. This research aims to merge Fast R-CNN and RPN together for optimizing computation.\n",
        "```\n",
        "\n",
        "Reference: Abstract section, page 1 _\"...Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks,...  We further merge RPN and Fast R-CNN into a single network...\"_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27BomlyIGB3B"
      },
      "source": [
        "##(2) It says \"Faster\", but what mechanism was used to make it faster? \n",
        "```markdown\n",
        "RPN used together with Fast R-CNN make it Faster R-CNN.\n",
        "```\n",
        "Reference: Faster R-CNN section, page 3: _\"...Using the recently popular terminology of neural\n",
        "networks with ‘attention’ [31] mechanisms, the RPN module tells the Fast R-CNN module where to look.\"_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi3rcPUVGIf_"
      },
      "source": [
        "## (3) How is the One-Stage method different from the Two-Stage method?\n",
        "\n",
        "One-stage  | Two-stage\n",
        "-------------------|------------------\n",
        "Detection       | Proposal + Detection\n",
        "OverFeat is a one-stage, class-specific detection pipeline | two-stage cascade consisting of class-agnostic proposals and class-specific detections.\n",
        "mAP of 53.9% on the same settings      | mAP of 58.7% on the same setting\n",
        "\n",
        "Reference: One-Stage Detection vs. Two-Stage Proposal + Detection section, page 10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSWZSWzmGLey"
      },
      "source": [
        "## (4) What is RPN?\n",
        "```markdown\n",
        "- RPN stands for Region Proposal Networks, takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score.\n",
        "```\n",
        "\n",
        "Reference: Region Proposal Networks, page 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcSFKJYPGOWT"
      },
      "source": [
        "## (5) What is RoI pooling?\n",
        "\n",
        "```markdown\n",
        "- RoI stands for Region of Interest, is a pooling method that uses max pooling to convert the\n",
        "features inside any valid region of interest into a small feature map with a fixed spatial extent of H ×W (e.g., 7 ×7),\n",
        "where H and W are layer hyper-parameters that are independent of any particular RoI\n",
        "```\n",
        "\n",
        "Reference: \n",
        "- Faster R-CNN, page 5. \n",
        "- RoI pooling layer in He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling\n",
        "in deep convolutional networks for visual recognition,” in\n",
        "European Conference on Computer Vision (ECCV), 2014."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_iTnfU5GQnE"
      },
      "source": [
        "## (6) What is the proper size for Anchor?\n",
        "\n",
        "```markdown\n",
        "randomly sample 256 anchors in an image to compute the loss function of a mini-batch, where the sampled \n",
        "positive and negative anchors have a ratio of up to 1:1. If there are fewer than 128 positive samples \n",
        "in an image, then pad the mini-batch with negative one.\n",
        "```\n",
        "\n",
        "Reference: 3.1.2 Loss Function, page 4-5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB59dAmzGSb_"
      },
      "source": [
        "## (7) What kind of data set is used and what kind of index value is obtained compared to the previous research?\n",
        "\n",
        "```markdown\n",
        "- Dataset: MS COCO\n",
        "- The experiment on Faster R-CNN compare to Fast R-CNN on mAP score shows that Faster R-CNN score is higher than Fast R-CNN in all tests.\n",
        "+ Faster R-CNN has 42.1% mAP@0.5 and 21.5% mAP@[.5, .95] on the COCO test-dev set. This is 2.8% higher for mAP@0.5\n",
        "and 2.2% higher for mAP@[.5, .95] than the Fast R-CNN.\n",
        "+ Using the COCO trainval set to train, Faster R-CNN has 42.7% mAP@0.5 and 21.9% mAP@[.5, .95] on the COCO test-dev set\n",
        "```\n",
        "\n",
        "Reference: 4.2 Experiments on MS COCO, page 10-11 and Table 10."
      ]
    }
  ]
}