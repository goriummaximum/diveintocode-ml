{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit67abafa0d2de4db49ae6ff50c42d1fc4",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchKMeans():\n",
    "    \"\"\"\n",
    "    K-means scratch implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "      Number of clusters\n",
    "    n_init : int\n",
    "      How many times to change the initial value of the center point for calculation\n",
    "    max_iter : int\n",
    "      Maximum number of iterations in one calculation\n",
    "    tol : float\n",
    "      Margin of error between the center point and the center of gravity, which is the reference for ending the iteration\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, n_init, max_iter, tol, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _init_mu_k(self, X):\n",
    "        rows = np.random.choice(X.shape[0], size=self.n_clusters, replace=False)\n",
    "        return X[rows, :]\n",
    "\n",
    "    def _compute_SSE(self, X, mu, r):\n",
    "        '''\n",
    "        Calculate SSE\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "          Features of training data\n",
    "        r : shape (n_samples, self.n_clusters)\n",
    "          cluster assignment\n",
    "        mu : shape (self.n_clusters, n_features)\n",
    "          center points\n",
    "        Return\n",
    "        ----------\n",
    "        SSE: shape (n_features, )\n",
    "          SSE\n",
    "        '''\n",
    "        SSE = 0.0\n",
    "        for k in range(0, self.n_clusters):\n",
    "            SSE += r[:, k] @ (X - mu[k, :])**2\n",
    "        return SSE\n",
    "    \n",
    "    def _allocate_r(self, X, mu):\n",
    "        \"\"\"\n",
    "        Allocate data points X to the nearest center point.\n",
    "        \"\"\"\n",
    "        distance_matrix = np.zeros((X.shape[0], n_clusters))\n",
    "        for k in range(0, self.n_clusters):\n",
    "            distance_matrix[:, k] = np.linalg.norm(X - mu[k, :], axis=1)\n",
    "        r = np.zeros((X.shape[0], n_clusters))\n",
    "        r[np.arange(len(r)), np.argmin(distance_matrix, axis=1)] = 1\n",
    "        return r\n",
    "\n",
    "    def _move_mu(self, X, r):\n",
    "        \"\"\"\n",
    "        Moves mu to the mean (center of gravity)\n",
    "        \"\"\"\n",
    "        mu = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(0, self.n_clusters):\n",
    "            mu[k, :] = X[r[:, k] == 1].mean(axis=0)\n",
    "        return mu\n",
    "\n",
    "    def _learning(self, X, init_mu):\n",
    "        mu = init_mu\n",
    "        r = self._allocate_r(X, mu)\n",
    "        prev_mu = mu\n",
    "        i = 0\n",
    "        while (i < self.max_iter):\n",
    "            mu = self._move_mu(X, r)\n",
    "            r = self._allocate_r(X, mu)\n",
    "            if (abs(np.sum(mu - prev_mu)) <= self.tol):\n",
    "                break\n",
    "            prev_mu = mu\n",
    "            i+=1\n",
    "        return mu, r\n",
    "\n",
    "    def _find_best_learnings(self, X):\n",
    "        SSE_list = []\n",
    "        mu_list = []\n",
    "        r_list = []\n",
    "        for i in range(0, self.n_init):\n",
    "            mu, r = self._find_best_learnings(X, self._init_mu_k(X))\n",
    "            SSE_list.append(self._compute_SSE(X, mu, r))\n",
    "            mu_list.append(mu)\n",
    "            r_list.append(r)\n",
    "            if verbose:\n",
    "                print(\"iter: {}   SSE: {}\".format(i, SSE_list[-1]))\n",
    "        min_idx = np.argmin(np.array(SSE_list))\n",
    "        return SSE_list[min_idx], mu_list[min_idx], r_list[min_idx]\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Calculate clustering by K-means\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"learning...\")\n",
    "            self.SSE, self.mu, self.r = self._find_best_learnings(X)\n",
    "        else:\n",
    "            self.SSE, self.mu, self.r = self._find_best_learnings(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Calculate which cluster the input data belongs to\n",
    "        \"\"\"\n",
    "        return self._allocate_r(X, self.mu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}